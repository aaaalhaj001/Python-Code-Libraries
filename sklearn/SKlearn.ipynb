{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use sklearn \n",
    "form sklearn model import model\n",
    "from sklearn import metrics\n",
    "var of model=model()\n",
    "var.fit(train,test)\n",
    "new value = you values\n",
    "var.predict(new value)\n",
    "print (metrics.accuracy_score(r,pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import labrty import sklearn.name model like import sklearn.cluster ,liner, cluster ,naive_bayes\n",
    "import sklearn.naive_bayes as np # الاحتمالات \n",
    "from sklearn import metrics # تستخم لعرفة نسة الصواب في النموذح\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.cluster import KMeans  # تجميع القيم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error #MSE\n",
    "metrics.mean_absolute_error #MAE\n",
    "np.sprt(metrics.mean_squared_error) #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for slit data train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "#var1name_train,var1name_test,var2name_train,var2name_test=train_test_split(name x_train data,name y_train data)\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE model var Name of modell=sklearn.name model   model = sklearn.linear_model.LinearRegression() \n",
    "model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tain model Name of Name of model.fit(data_tain,data_test)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to test data name of model.predict(new data)\n",
    "x_new=[]\n",
    "model.predict(X_new)\n",
    "print (metrics.accuracy_score(y,pr)\n",
    "       \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.20, random_state=42) \n",
    "from sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Classification Performance Measures  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-15dcd54577c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "confusion_matrix(y_test,pm)\n",
    "precision_score(y_test,pm)\n",
    "recall_score(y_test,pm)\n",
    "f1_score(y_test,pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-07b949348523>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtree_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtree_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#اظهار الشجرة\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(x, y)\n",
    "#اظهار الشجرة\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(\n",
    "tree_clf,\n",
    "out_file=image_path(\"tree.dot\"),\n",
    "feature_names=data.feature_names[2:],\n",
    "class_names=data.target_names,\n",
    "rounded=True,\n",
    "filled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])   #proba = احتمالات\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import naive_bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7fa0f6683819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'rf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m voting='hard')\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "knn_clf= KNeighborsClassifier()\n",
    "bgc_clf=BaggingClassifier()\n",
    "gbc_clf=GradientBoostingClassifier()\n",
    "abc_clf= AdaBoostClassifier()\n",
    "\n",
    "for v in ['hard','soft']:\n",
    "    voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('tree', tree_clf),('knn', knn_clf),('bg', bgc_clf),\n",
    "                ('gbc', gbc_clf),('abc', abc_clf)]\n",
    "\n",
    "    voting=v)\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    for clf in (log_clf, rnd_clf, svm_clf,tree_clf,knn_clf,bgc_clf,gbc_clf,abc_clf,voting_clf):\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print(v,clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "abr_reg = AdaBoostRegressor()\n",
    "rnd_reg = RandomForestRegressor()\n",
    "br= BaggingRegressor()\n",
    "tree_reg =  DecisionTreeRegressor()\n",
    "knn_reg= KNeighborsRegressor()\n",
    "gbr_reg = GradientBoostingRegressor()\n",
    "svr_reg= SVR()\n",
    "voting_reg =VotingRegressor(\n",
    "estimators=[('ad', abr_reg), ('rf', rnd_reg), ('br', br), ('tree', tree_reg),('knn', knn_reg),('gbr',gbr_reg),'svr',svr_reg])\n",
    "voting_reg.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for reg in (gbr_reg, rnd_reg, abr_reg,tree_reg,knn_reg,svr_reg, voting_reg):\n",
    "    reg.fit(x_train,y_train)\n",
    "    y_pred = reg.predict(x_test)\n",
    "    print(reg.__class__.__name__,voting_reg.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler=StandardScaler()\n",
    "Scaler.fit(x)\n",
    "x_Scaler=Scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=5)\n",
    "pca.fit(X)\n",
    "x_pca=pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gid CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\n",
    "clf.fit(x_train,y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GridSearchCV to select best Random Forest Classifier \n",
    "rf_clf=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "   \n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rf_clf,param_grid=param_grid,cv=5)\n",
    "CV_rfc.fit(x_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(3,-3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(x_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsRegressor()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(x_train,y_train)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roc_curve, Auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve ,auc\n",
    "y_pred_proba = lr_clf.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test,pred)\n",
    "auc_lr_clf = auc(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='Logistic Regression(auc = %0.3f)'% auc_lr_clf )\n",
    "plt.xlabel('Tpr')\n",
    "plt.xlabel('Fpr')\n",
    "plt.title('Logistic Regression ROC curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "logistic_fpr, logistic_tpr, threshold = roc_curve(y_test, y_pred_logistic)\n",
    "auc_logistic = auc(logistic_fpr, logistic_tpr)\n",
    "\n",
    "svm_fpr, svm_tpr, threshold = roc_curve(y_test, y_pred_svm)\n",
    "auc_svm = auc(svm_fpr, svm_tpr)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.plot(svm_fpr, svm_tpr, linestyle='-', label='SVM (auc = %0.3f)' % auc_svm)\n",
    "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='Logistic (auc = %0.3f)' % auc_logistic)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if need lasso change ridge for lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge=Ridge()\n",
    "parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}\n",
    "ridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "ridge_regressor.fit(X,y)\n",
    "\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2403529e55ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_lasso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel_lasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpred_train_lasso\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_lasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_train_lasso\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# if need ridge change lasso for ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "model_lasso = Lasso(alpha=0.01)\n",
    "model_lasso.fit(X_train, y_train) \n",
    "pred_train_lasso= model_lasso.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "pred_test_lasso= model_lasso.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print(r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=5)),\n",
    "                     ('lr_classifier',LogisticRegression(random_state=0))])\n",
    "\n",
    "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
    "                     ('pca2',PCA(n_components=5)),\n",
    "                     ('dt_classifier',DecisionTreeClassifier())])\n",
    "\n",
    "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
    "                     ('pca3',PCA(n_components=5)),\n",
    "                     ('rf_classifier',RandomForestClassifier())])\n",
    "\n",
    "pipeline_knn=Pipeline([('scalar4',StandardScaler()),\n",
    "                     ('pca4',PCA(n_components=5)),\n",
    "                     ('knn_classifier',KNeighborsClassifier())])\n",
    "\n",
    "\n",
    "pipeline_svm=Pipeline([('scalar5',StandardScaler()),\n",
    "                     ('pca5',PCA(n_components=5)),\n",
    "                     ('svm_classifier',SVC())])\n",
    "\n",
    "\n",
    "pipeline_bc=Pipeline([('scalar6',StandardScaler()),\n",
    "                     ('pca6',PCA(n_components=5)),\n",
    "                     ('bc_classifier',BaggingClassifier())])\n",
    "\n",
    "pipeline_gbc=Pipeline([('scalar7',StandardScaler()),\n",
    "                     ('pca6',PCA(n_components=5)),\n",
    "                     ('gb_classifier',GradientBoostingClassifier())])\n",
    "\n",
    "pipeline_abc=Pipeline([('scalar8',StandardScaler()),\n",
    "                     ('pca8',PCA(n_components=5)),\n",
    "                     ('ab_classifier',AdaBoostClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e4298ec16ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[1;33m(\u001b[0m\u001b[1;34m'pca1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      ('lr_Regression',LinearRegression())])\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=6)),\n",
    "                     ('lr_Regression',LinearRegression())])\n",
    "\n",
    "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
    "                     ('pca2',PCA(n_components=6)),\n",
    "                     ('tree_Regressorr',DecisionTreeRegressor())])\n",
    "\n",
    "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
    "                     ('pca3',PCA(n_components=6)),\n",
    "                     ('rf_Regressorr',RandomForestRegressor())])\n",
    "\n",
    "\n",
    "pipeline_knn=Pipeline([('scalar4',StandardScaler()),\n",
    "                     ('pca4',PCA(n_components=6)),\n",
    "                     ('knn_Regressor',KNeighborsRegressor(n_neighbors=4,leaf_size=1,p=1))])\n",
    "\n",
    "\n",
    "pipeline_svm=Pipeline([('scalar5',StandardScaler()),\n",
    "                     ('pca5',PCA(n_components=6)),\n",
    "                     ('svm_Regression',SVR())])\n",
    "\n",
    "pipeline_bc=Pipeline([('scalar6',StandardScaler()),\n",
    "                     ('pca6',PCA(n_components=5)),\n",
    "                     ('bc_Regressor',BaggingRegressor())])\n",
    "\n",
    "pipeline_gbc=Pipeline([('scalar7',StandardScaler()),\n",
    "                     ('pca6',PCA(n_components=5)),\n",
    "                     ('gb_Regressor',GradientBoostingRegressor())])\n",
    "\n",
    "pipeline_abc=Pipeline([('scalar8',StandardScaler()),\n",
    "                     ('pca8',PCA(n_components=5)),\n",
    "                     ('ab_Regressor',AdaBoostRegressor())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coss val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validation\n",
    "x_train,x_test,y_train,y_test= cross_validation.train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold   \n",
    "skf = StratifiedKFold(n_splits=50,shuffle=True)\n",
    "skf.get_n_splits(X,y) # Number of splits of X\n",
    "\n",
    "# Printing the Train & Test Indices of splits\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=\"Glucose\", y=\"Outcome\", data=data,\n",
    "                 logistic=True, n_boot=500, y_jitter=.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmean=KMeans()\n",
    "y_pred = kmean.fit_predict(x_Scaler)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "model = DBSCAN(eps=0.25, min_samples=6).fit(x_Scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "ap=AffinityPropagation()\n",
    "y_pred = ap.fit_predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ac=AgglomerativeClustering()\n",
    "y_pred = ac.fit_predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sctr = ax.scatter(X[:, 0], X[:, 1], c=ap.labels_, s=140, alpha=0.9,\n",
    "                 cmap=plt.cm.Set1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
