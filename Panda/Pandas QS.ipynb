{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandes doc https://pandas.pydata.org/docs/reference/index.html\n",
    "import pandas as pd\n",
    "#shift+tab  استعراض الملف للدلة"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shift+tab for docs for fuction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read a tabular data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data form table\n",
    "order=pd.read_table(\"http://bit.ly/chiporders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>item_name</th>\n",
       "      <th>choice_description</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chips and Fresh Tomato Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Izze</td>\n",
       "      <td>[Clementine]</td>\n",
       "      <td>$3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nantucket Nectar</td>\n",
       "      <td>[Apple]</td>\n",
       "      <td>$3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chips and Tomatillo-Green Chili Salsa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Chicken Bowl</td>\n",
       "      <td>[Tomatillo-Red Chili Salsa (Hot), [Black Beans...</td>\n",
       "      <td>$16.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  quantity                              item_name  \\\n",
       "0         1         1           Chips and Fresh Tomato Salsa   \n",
       "1         1         1                                   Izze   \n",
       "2         1         1                       Nantucket Nectar   \n",
       "3         1         1  Chips and Tomatillo-Green Chili Salsa   \n",
       "4         2         2                           Chicken Bowl   \n",
       "\n",
       "                                  choice_description item_price  \n",
       "0                                                NaN     $2.39   \n",
       "1                                       [Clementine]     $3.39   \n",
       "2                                            [Apple]     $3.39   \n",
       "3                                                NaN     $2.39   \n",
       "4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print order & print 5 row form data\n",
    "order\n",
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use fun sep for splet data  \n",
    "#use fun header for change the header like her i change the heder in none vlaue\n",
    "#use fun names for input name for you header\n",
    "#use fun skiprows=None or skipfooter=None for del note \n",
    "user_co=['user_id', 'age', 'gnder','occupation','zip_code']\n",
    "user=pd.read_table(\"http://bit.ly/movieusers\",sep=\"|\",header=None,names=user_co)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a pandas Series from a DataFrame,create and add column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Colors Reported</th>\n",
       "      <th>Shape Reported</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>NY</td>\n",
       "      <td>6/1/1930 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Willingboro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NJ</td>\n",
       "      <td>6/30/1930 20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Holyoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>CO</td>\n",
       "      <td>2/15/1931 14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>KS</td>\n",
       "      <td>6/1/1931 13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>New York Worlds Fair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>NY</td>\n",
       "      <td>4/18/1933 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18236</td>\n",
       "      <td>Grant Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>IL</td>\n",
       "      <td>12/31/2000 23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18237</td>\n",
       "      <td>Spirit Lake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>IA</td>\n",
       "      <td>12/31/2000 23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18238</td>\n",
       "      <td>Eagle River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WI</td>\n",
       "      <td>12/31/2000 23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18239</td>\n",
       "      <td>Eagle River</td>\n",
       "      <td>RED</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>WI</td>\n",
       "      <td>12/31/2000 23:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18240</td>\n",
       "      <td>Ybor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>FL</td>\n",
       "      <td>12/31/2000 23:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18241 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City Colors Reported Shape Reported State  \\\n",
       "0                    Ithaca             NaN       TRIANGLE    NY   \n",
       "1               Willingboro             NaN          OTHER    NJ   \n",
       "2                   Holyoke             NaN           OVAL    CO   \n",
       "3                   Abilene             NaN           DISK    KS   \n",
       "4      New York Worlds Fair             NaN          LIGHT    NY   \n",
       "...                     ...             ...            ...   ...   \n",
       "18236            Grant Park             NaN       TRIANGLE    IL   \n",
       "18237           Spirit Lake             NaN           DISK    IA   \n",
       "18238           Eagle River             NaN            NaN    WI   \n",
       "18239           Eagle River             RED          LIGHT    WI   \n",
       "18240                  Ybor             NaN           OVAL    FL   \n",
       "\n",
       "                   Time  \n",
       "0        6/1/1930 22:00  \n",
       "1       6/30/1930 20:00  \n",
       "2       2/15/1931 14:00  \n",
       "3        6/1/1931 13:00  \n",
       "4       4/18/1933 19:00  \n",
       "...                 ...  \n",
       "18236  12/31/2000 23:00  \n",
       "18237  12/31/2000 23:00  \n",
       "18238  12/31/2000 23:45  \n",
       "18239  12/31/2000 23:45  \n",
       "18240  12/31/2000 23:59  \n",
       "\n",
       "[18241 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\")\n",
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ufo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-e01eed400599>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-e01eed400599>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    movies=pd.read_csv(\"http://bit.ly/imdbratings\",usecols=[0:4])\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#use var[\"name column\"] for print one column\n",
    "#short cut var.namecolumn   note not use it in var have space\n",
    "#note 2 not use fun in var like name in var\n",
    "ufo[\"State\"] \n",
    "ufo.State\n",
    "#use fun usecols for show columns u needs\n",
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\",usecols=[0:4])\n",
    "movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create new column\n",
    "#use var[\"new column\"]= value need add like add two var in one column\n",
    "#note use var[\"name column\"] for use add not use .\n",
    "ufo['loc']=ufo.City+','+ufo.State\n",
    "ufo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some pandas commands end with parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use fun describe() in mean and std and cout ets........ \n",
    "movies.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE dtypes for types of value movies.dtype\n",
    "#USE shapes for count column and row movies.shape\n",
    "type(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rename columns in a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\")\n",
    "ufo\n",
    "\n",
    "#for rename use fun rename() var.rename(column={old name , new name})\n",
    "ufo.rename(columns={'City':'city'})\n",
    "#use anther way to change name for columnn, create list like \n",
    "#list1=[\"new_name1\",\"new_name2\",\"new_name.3\"] and wite you list= ufo.columns\n",
    "ufo_cl=[\"city\",\"colors_Reported\",\"shape_Reported\",\"tate\",\"time\"]\n",
    "ufo.columns= ufo_cl\n",
    "#use anther way to change name for columnn,create list like \n",
    "#list1=[\"new_name1\",\"new_name2\",\"new_name.3\"] ,\n",
    "#wite in pd.read_csv(\"path_csv\",names=youlist,header=0)\n",
    "ufo_cl=[\"city\",\"colorsReported\",\"shapeReported\",\"state\",\"time\"]\n",
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\",names=ufo_clo,header=0)\n",
    "ufo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove columns from a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\")\n",
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use drop fun for drop cplumns or row for drop column use axis=1 , row axis =0\n",
    "# for drop 1 col or ro use drop('name') and multye use drop([\"name1\",name2],inplace=True)\n",
    "ufo.drop('Colors Reported', axis=1,inplace=True)\n",
    "ufo.drop(['Time','Colors Reported'], axis=1,inplace=True)\n",
    "ufo.drop(0,axis=0,inplace=True)\n",
    "ufo.drop([0,1],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort a pandas DataFrame or a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use sort value for scendings or adscendings\n",
    "movies.sort_values(\"title\")\n",
    "movies.sort_values([\"title\",\"star_rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter rows of a pandas DataFrame by column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use var.loc for filter rows and column in pandans\n",
    "#var.loc[condtion ,row or columns] or we can use var.[var.col or row condtion]\n",
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\")\n",
    "movies[movies.duration >=200]\n",
    "movies.loc[movies.duration >=200,\"genre\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I apply multiple filter criteria to a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for multiple filter use () bewteen condection and use & and , | or\n",
    "#var[(var.name cond1)& or | (var.name cond1)]\n",
    "movies[(movies.duration >=200) & (movies.genre >=\"Drama\" )]\n",
    "movies[(movies.duration >=200) | (movies.genre >=\"Drama\") | (movies.genre >=\"Action\" )]\n",
    "movies.genre.isin([\"Drama\",\"Action\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"axis\" parameter in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.drop([\"actors_list\"],axis=1).head()\n",
    "movies.mean(axis=1) #or movies.mean(\"columns\") man for rows #mean for cloumns\n",
    "movies.mean(axis=0) #or movies.mean(\"index\")or movies.mean(\"rows\") #man for rows #man for rows \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use string methods in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=pd.read_table(\"http://bit.ly/chiporders\")\n",
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if you need str fun use in pandas var.name.str.namefun()\n",
    "# if need multyp fun in pandas var.name.str.namefun.str.namefun2 , if you need more fun vist the\n",
    "#websae :https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.capitalize.html?highlight=str\n",
    "order.item_name.str.upper()\n",
    "order.item_name.str.upper().str.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use change type for change int str use math\n",
    "#for now type of data use fun dtypes() var.dtypes()\n",
    "# for change the type of data use var.namevar.astype(new types)\n",
    "#for use multp fn use var.namecolumn.str.name.asdtype(new types))\n",
    "order.dtypes\n",
    "order.order_id.astype(float)\n",
    "order.item_price.str.replace(\"$\",\"\").astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"groupby\" in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink=pd.read_csv(\"http://bit.ly/drinksbycountry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gropby for dived the data by gruop var.groupby(\"namecolumn\").mean or min or max \n",
    "#if need one value use var.groupby(\"namecolumn\").namecloumn2.mean or min or max \n",
    "drink.head()\n",
    "drink.groupby(\"continent\").wine_servings.mean()\n",
    "drink.groupby(\"continent\").max()\n",
    "#just africa cuontry\n",
    "drink[drink.continent=='Africa']\n",
    "#use multp maen and min and max and sd use agg var.groupby(\"namecolumn\").agg(['mean','min' , 'max'])\n",
    "drink.groupby(\"continent\").wine_servings.agg([\"mean\",\"min\",\"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plot data use %matplotlib inline \n",
    "#and add in data like var.groupby(\"namecolumn\").mean or min or max .plot(kind=bar, pie,line )\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drik.groupby(\"cotiet\").mea().plot(kid='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore a pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes\n",
    "movies.genre.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use describe for data not number show count ,unique ,top ,freg\n",
    "# var. namecolumns.describe() and can show one of describes use\n",
    "#var. namecolumns.one of describe() \n",
    "movies.genre.describe()\n",
    "movies.genre.unique()\n",
    "movies.genre.nunique()\n",
    "#and you can cross to column in one table use pd.crosstab(namecolumns1,movies.namecolumns)\n",
    "pd.crosstab(movies.genre,movies.content_rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies.duration.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle missing values in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\")\n",
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufo.isnull().sum() #chack value is null true or notnull false \n",
    "ufo.notnull().sum()  #chack value is null false or notnull ture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ufo[ufo.City.isnull()]# show value is null\n",
    "ufo.dropna(how=\"any\").count() #drop null value any value is null\n",
    "ufo.dropna(how=\"all\").count()#drop null value all value is null\n",
    "ufo.dropna(subset=[\"City\",\"Shape Reported\"],how=\"any\")\n",
    "ufo[\"Shape Reported\"].value_counts(dropna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# know about the pandas index? (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink=pd.read_csv(\"http://bit.ly/drinksbycountry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink[drink.continent==\"South America\"] #filter data to south america countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.set_index(\"country\",inplace=True)#change the index\n",
    "drink.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drink.index #show the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.loc[\"USA\",\"beer_servings\"] # show spacfak value var,loc[index,column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.index.name=None # clean the index name use name=None\n",
    "drink.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# know about the pandas index? (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.continent.value_counts().sort_index()#sort the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new series var=pd.Series([value1,value2],index=[\"index1\",\"index2\"],name='namecolmn')\n",
    "people=pd.Series([3000000,850000],index=[\"Albania\",\"Algeria\"],name='PP')\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink.beer_servings*people#use some math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([drink,people],axis=1).head()#macth new data to data old data\n",
    "#pd.concat([orgin data,new var data],axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select multiple rows and columns from a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\")\n",
    "ufo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc for filtering and select lebal(r,c) loc[r,c]\n",
    "ufo.loc[0,\"City\"]\n",
    "ufo.loc[[0,1,2],[\"City\",\"State\"]]\n",
    "ufo.loc[:,'State']# can use list\n",
    "ufo.loc[0:3,\"City\":\"State\"]#list of select var.loc[r:,c:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use loc for condecion var.loc[var.cond, cond2 or column]\n",
    "ufo.loc[ufo.City==\"Willingboro\",\"State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc for filtering and select int(r,c) like use range in python iloc[range r, range c] li\n",
    "ufo.iloc[0:4,0:3] \n",
    "ufo.iloc[0:3,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use in loc or iloc\n",
    "#ix use for mix value label and number\n",
    "ufo.ix[0:2,0:2]#use same number in end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the \"inplace\" parameter in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use inplace=True when and use operation and facet anthoer operation like in drop or change index you need use inplace\n",
    "#not use inplace you facect code line like\n",
    "#var.drop(\"city\"axis=1) if go to anther line code is not drop column \n",
    "# and if use inplace in code var.drop(\"city\",axis=1,inplace=True) drop will work \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# work with dates and times in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ufo=pd.read_csv(\"http://bit.ly/uforeports\")\n",
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.str.slice(-5,-3).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chage str to datatime var[\"col\"]=pd.datetime(var.clo)\n",
    "ufo[\"Time\"]=pd.datetime(ufo.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Published '] = pd.to_datetime(data.Published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.Time.dt.week_name \n",
    "ufo.Time.dt.year\n",
    "# have more in doc find dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use condtion\n",
    "ta=pd.datetime(\"1/1/1999\")\n",
    "ufo[ufo[\"time\"]>ta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dummy variables in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_co=['user_id', 'age', 'gnder','occupation','zip_code']\n",
    "user=pd.read_table(\"http://bit.ly/movieusers\",sep=\"|\",header=None,names=user_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for create dummy variables you use pd.get_dummies(va,column=[\"col1\",\"col2\"]drop_first=True)  \n",
    "m=pd.get_dummies(user.gnder,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#دك البيانات من الافقين\n",
    "data=pd.concat([df1,df2], axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([user,m], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find and remove duplicate rows in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_co=['user_id', 'age', 'gnder','occupation','zip_code']\n",
    "user=pd.read_table(\"http://bit.ly/movieusers\",sep=\"|\",header=None,names=user_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.set_index('user_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find duplicated data var.loc[vr.col.duplicated(),:]\n",
    "user.loc[user.zip_code.duplicated(),:]\n",
    "#for dorp dup use var.drop_duplicates(subset=[\"col1\",\"col2\"])\n",
    "user.drop_duplicates(subset=[\"age\",\"zip_code\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avoid a SettingWithCopyWarning in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"http://bit.ly/imdbratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for find and fix null value\n",
    "movies[movies.content_rating.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies.content_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fix value\n",
    "movies.loc[movies.content_rating==\"NOT RATED\",\"content_rating\"]np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix copywarning use fun copy to say this copy form org data\n",
    "top=movies.loc[movies.duration >= 140,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.loc[0,'duration']=150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change display options in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for change option can use\n",
    "pd.get_option() \n",
    "pd.set_option()  # change option\n",
    "pd.reset_option()\n",
    "pd.describe_option('all') # find option you need \n",
    "#doc set_option https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a pandas DataFrame from another object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dataframe df=pd.DataFrame({\"column\":value1,\"column2\":value2})\n",
    "#create serise  pd.series([value,value],index[1,2],name=\"name series\")\n",
    "#save array is dataframe arr=np.array[1,2,3]  pd.Dataframe(name array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply a function to a pandas Series or DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_co=['user_id', 'age', 'gnder','occupation','zip_code']\n",
    "user=pd.read_table(\"http://bit.ly/movieusers\",sep=\"|\",header=None,names=user_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use apply to apply fun python in pandans and my fun python\n",
    "user[\"sex\"]=user.gnder.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked=pd.get_dummies(t_train.Embarked,drop_first=True)\n",
    "pd.concat([t_train,embarked], axis=1,inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
